{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add a new cell, type '# %%'\n",
    "# To add a new markdown cell, type '# %% [markdown]'\n",
    "# %%\n",
    "import pywt\n",
    "import numpy as np \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat\n",
    "from entropy import *\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "# %%\n",
    "data = loadmat('BCI_2003_datasetIII.mat')\n",
    "X = data['x_train']\n",
    "y = data['y_train']\n",
    "\n",
    "\n",
    "# %%\n",
    "\"\"\"\n",
    "Feature Selection and Pre-processing\n",
    "\n",
    "\"\"\"\n",
    "# Remove 0-3s from the signal\n",
    "\n",
    "\n",
    "# %%\n",
    "X = X[384:, :, :]\n",
    "# sliding window PSE\n",
    "def window_pse(signal, size= 128):\n",
    "    zero = np.zeros(len(signal))\n",
    "    for i in range(len(signal)):\n",
    "        zero[i] = spectral_entropy(np.abs(signal[i: size+i]), 128, method='welch', normalize=True)\n",
    "    return zero\n",
    "\n",
    "def moving_average(x, w=16):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "\n",
    "# %%\n",
    "i = moving_average(X[:,0,49])\n",
    "n =  i.shape[0]\n",
    "print(n)\n",
    "\n",
    "\n",
    "# %%\n",
    "n =  i.shape[0]\n",
    "X_tf = np.zeros((n,3,140))\n",
    "for i in range(140):\n",
    "    for j in range(3):\n",
    "        X_tf[:,j,i] = moving_average(X[:,j,i]) \n",
    "\n",
    "\n",
    "# %%\n",
    "for i in range(140):\n",
    "    for j in range(3):\n",
    "        X_tf[:,j,i] = window_pse(X_tf[:,j,i]) \n",
    "\n",
    "\n",
    "# %%\n",
    "X_tf = X_tf[:700,:,:]\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "left_index = np.argwhere(y == 1)\n",
    "right_index = np.argwhere(y == 2)\n",
    "\n",
    "X_left = X[:,:,left_index[:,0]]\n",
    "# \n",
    "c3l_mean = np.mean(X_left[:,0,:], axis=1)\n",
    "czl_mean = np.mean(X_left[:,1,:], axis=1)\n",
    "c4l_mean = np.mean(X_left[:,2,:], axis=1)\n",
    "\n",
    "X_right = X[:,:,right_index[:,0]]\n",
    "#\n",
    "c3r_mean = np.mean(X_right[:,0,:], axis=1)\n",
    "czr_mean = np.mean(X_right[:,1,:], axis=1)\n",
    "c4r_mean = np.mean(X_right[:,2,:], axis=1)\n",
    "\n",
    "\n",
    "# %%\n",
    "c3l_mean = moving_average(c3l_mean)\n",
    "c3r_mean = moving_average(c3r_mean)\n",
    "\n",
    "pse3_left = window_pse(c3l_mean)\n",
    "pse3_right = window_pse(c3r_mean)\n",
    "\n",
    "t1, f1 , sft3_left = signal.stft(c3l_mean, 265, nperseg=100)\n",
    "t2, f1, sft3_right= signal.stft(c3r_mean, 256, nperseg=100)\n",
    "\n",
    "f, ax = plt.subplots(2, figsize=(15,15) ,sharey=False)\n",
    "\n",
    "ax[0].plot(t1, np.abs(sft3_left), color='black')\n",
    "ax[0].plot(t2, np.abs(sft3_right), color='red')\n",
    "ax[0].set_title('Short Time FFT')\n",
    "\n",
    "ax[0].set(xlabel='Frequency', ylabel='Magnitude')\n",
    "ax[0].legend(('left', 'right'))\n",
    "\n",
    "ax[1].plot(pse3_left, color='black')\n",
    "ax[1].plot(pse3_right, color='red')\n",
    "ax[1].set_title('Power Spectral Entropy')\n",
    "\n",
    "ax[1].set(xlabel='Time', ylabel='Power Spectral Entropy')\n",
    "ax[1].legend(('left', 'right'))\n",
    "\n",
    "xlables = ['Frequency', 'Time']\n",
    "ylables = ['Magnitude', 'Entropy']\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# %%\n",
    "\"\"\"\n",
    "Feature Extraction\n",
    "\n",
    "\"\"\"\n",
    "X_tf = np.zeros((140,3))\n",
    "for i in range(140):\n",
    "    for j in range(3):\n",
    "        x_mean = moving_average(X[:,j,i])\n",
    "        pse = window_pse(x_mean)\n",
    "        xx = pse[0:400]\n",
    "        ft = xx[~np.isnan(xx)]\n",
    "        X_tf[i,j] = np.mean(ft)\n",
    "#\n",
    "X_f = np.zeros((140,3))\n",
    "\n",
    "for i in range(140):\n",
    "    for j in range(3):\n",
    "        yl = X_tf[:,j,i][~np.isnan(X_tf[:,j,i])]\n",
    "        X_f[i,j] = np.mean(yl)\n",
    "       \n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "# PCA Decomposion\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_tf)\n",
    "\n",
    "X_pca = pca.transform(X_tf)\n",
    "\n",
    "\n",
    "# %%\n",
    "\"\"\"\n",
    "Train/Test Split\n",
    "\n",
    "\"\"\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca , y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "# %%\n",
    "\"\"\"\n",
    "Non-linear Support Vector Machine IMPLEMENTATION\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# %%\n",
    "classifier = SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [(\"Confusion matrix\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(classifier, X_test, y_test,\n",
    "                                 display_labels=['left', 'right'],\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# %%\n",
    "from sklearn import metrics\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# %%\n",
    "\"\"\"\n",
    "KNN\n",
    "\"\"\"\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k_range = range(1,26)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y2_pred = knn.predict(X_test)\n",
    "    scores.append(metrics.accuracy_score(y_test, y2_pred))\n",
    "\n",
    "\n",
    "# %%\n",
    "mx = max(scores)\n",
    "n_max  = scores.index(mx) + 1\n",
    "print(mx, n_max)\n",
    "\n",
    "\n",
    "# %%\n",
    "knn = KNeighborsClassifier(n_neighbors=n_max)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# %%\n",
    "titles_options = [(\"Confusion matrix\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(knn, X_test, y_test,\n",
    "                                 display_labels=['left', 'right'],\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# %%\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_knn))\n",
    "\n",
    "\n",
    "# %%\n",
    "\"\"\"\n"
   ]
  }
 ]
}
